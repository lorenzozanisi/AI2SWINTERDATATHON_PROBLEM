{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFP_VAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgsKLnPPVT/cuAkO8Tov+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzozanisi/AI2SWINTERDATATHON_PROBLEM/blob/main/TFP_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV1ikdxzdnbk"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfkl\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability import distributions as tfd\n",
        "from tensorflow_probability import layers as tfpl\n",
        "import tensorflow as tf\n",
        "from scipy.special import factorial\n",
        "from google.colab import files\n",
        "import shutil"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuvAVVtAeo7V"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "N8yMXMQzerpS",
        "outputId": "a9dfa6a2-621d-4ed1-cec7-7cacbc7a9f05"
      },
      "source": [
        "data = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c21ede25-5c51-4b7f-bb55-c51811a8684e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c21ede25-5c51-4b7f-bb55-c51811a8684e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving coad_major.txt to coad_major (1).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al-NWx2Yetx5"
      },
      "source": [
        "data = pd.read_csv('coad_major.txt', sep=',', header=None)\n",
        "\n",
        "data = data.T #rows= sequence, y= position in the genome\n",
        "\n",
        "train_size = int(len(data)*0.75)\n",
        "train = np.array(data.iloc[:train_size]).astype(np.float32)\n",
        "test = np.array(data.iloc[train_size:]).astype(np.float32)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWqvBrUaKXq",
        "outputId": "ab76ae19-59a5-4f24-ce7a-1ef748b5369a"
      },
      "source": [
        "np.array([train,train]).shape   ####WORK ON THIS!!"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 285, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSfOKMS2e9cJ"
      },
      "source": [
        "input_shape = data.shape[1]\n",
        "batch_size = 16\n",
        "train = tf.data.Dataset.from_tensor_slices(train).shuffle(train_size).batch(batch_size)\n",
        "test = tf.data.Dataset.from_tensor_slices(test).shuffle(train_size).batch(batch_size)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdlzLj9N3Zj9",
        "outputId": "561c7e9f-66d7-48c0-a92f-da711e5bd2c7"
      },
      "source": [
        "train.take(1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: (None, 10000), types: tf.float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9FkKwupfF8h"
      },
      "source": [
        "# from TFP API, https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_qMl75QfLY0"
      },
      "source": [
        "latent_dim = 16\n",
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dim),scale=1),reinterpreted_batch_ndims=1)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyzZGJsZiixQ"
      },
      "source": [
        "encoder = tf.keras.Sequential(\n",
        "            [tfkl.InputLayer(input_shape=input_shape),\n",
        "             tfkl.Dense(5000, activation='relu',name='encoder_dense1'),\n",
        "             tfkl.Dense(1000, activation='relu', name='encoder_dense2'),\n",
        "             tfkl.Dense(500, activation='relu',name='encoder_dense3'),\n",
        "             tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim), activation='relu',name='encoder_dense4'), #the number of parameters that are needed to describe the multivariate\n",
        "             tfpl.MultivariateNormalTriL(latent_dim, activity_regularizer=tfpl.KLDivergenceRegularizer(prior))\n",
        "            ])\n",
        "\n",
        "\n",
        "\n",
        "decoder = tf.keras.Sequential(\n",
        "            [tfkl.InputLayer(input_shape=[latent_dim]),\n",
        "             tfkl.Dense(500,activation='relu'),\n",
        "             tfkl.Dense(1000, activation='relu'),\n",
        "             tfkl.Dense(5000, activation='relu'),\n",
        "             tfkl.Dense(tfpl.IndependentPoisson.params_size(input_shape), activation='relu'),\n",
        "             tfpl.IndependentPoisson(input_shape)        \n",
        "            ])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKte8qf7ipp9"
      },
      "source": [
        "model = tf.keras.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[0]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLh_ViRIv_nl"
      },
      "source": [
        "negloglik = lambda x,rv : -rv.log_prob(x)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgKYymt2wWRp"
      },
      "source": [
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
        "            loss=negloglik)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwznF5FBOwZl",
        "outputId": "a8299bde-be44-42aa-bb90-c7b3f2f07b28"
      },
      "source": [
        "model.fit(train, epochs=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 1/18 [>.............................] - ETA: 9s - loss: 3.6541WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 2/18 [==>...........................] - ETA: 8s - loss: 3.6942WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 3/18 [====>.........................] - ETA: 8s - loss: 3.2680WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 4/18 [=====>........................] - ETA: 7s - loss: 3.4554WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 5/18 [=======>......................] - ETA: 6s - loss: 3.3915WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 6/18 [=========>....................] - ETA: 6s - loss: 3.2741WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 7/18 [==========>...................] - ETA: 5s - loss: 3.1689WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 8/18 [============>.................] - ETA: 5s - loss: 3.1557WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 9/18 [==============>...............] - ETA: 4s - loss: 3.0697WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "10/18 [===============>..............] - ETA: 4s - loss: 3.0042WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "11/18 [=================>............] - ETA: 3s - loss: 3.1634WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "12/18 [===================>..........] - ETA: 3s - loss: 3.1240WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "13/18 [====================>.........] - ETA: 2s - loss: 3.1639WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "14/18 [======================>.......] - ETA: 2s - loss: 3.2182WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "15/18 [========================>.....] - ETA: 1s - loss: 3.2238WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "16/18 [=========================>....] - ETA: 1s - loss: 3.2200WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 3.1978WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "18/18 [==============================] - 10s 535ms/step - loss: 3.2267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2a9bc7a2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dW3TYKIM3rw",
        "outputId": "fee1d140-d01e-4321-d8a7-692c9d4c9e63"
      },
      "source": [
        "model.variables"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'encoder_dense1/kernel:0' shape=(10000, 5000) dtype=float32, numpy=\n",
              " array([[ 0.00957055, -0.01487634, -0.01079694, ...,  0.00116258,\n",
              "         -0.01720769, -0.01758911],\n",
              "        [ 0.00143564, -0.00455323,  0.01307984, ...,  0.0103692 ,\n",
              "          0.00580201,  0.00595688],\n",
              "        [-0.00117194,  0.00762449, -0.00239741, ..., -0.0004887 ,\n",
              "          0.00967936, -0.0019867 ],\n",
              "        ...,\n",
              "        [ 0.01595523,  0.0077684 ,  0.01204156, ..., -0.0113468 ,\n",
              "          0.01036847,  0.00789162],\n",
              "        [ 0.00643632,  0.00841137, -0.01422711, ..., -0.0040859 ,\n",
              "         -0.0217581 ,  0.01378467],\n",
              "        [ 0.00572278,  0.0077914 , -0.02123341, ..., -0.02331766,\n",
              "         -0.00293705, -0.02038405]], dtype=float32)>,\n",
              " <tf.Variable 'encoder_dense1/bias:0' shape=(5000,) dtype=float32, numpy=\n",
              " array([ 0.        ,  0.00212105, -0.00600504, ..., -0.00466226,\n",
              "        -0.00600503,  0.00028827], dtype=float32)>,\n",
              " <tf.Variable 'encoder_dense2/kernel:0' shape=(5000, 1000) dtype=float32, numpy=\n",
              " array([[-0.01931766, -0.02899963,  0.0111625 , ..., -0.01277561,\n",
              "         -0.00609712,  0.03117618],\n",
              "        [ 0.02388062, -0.00490875,  0.0135965 , ..., -0.03120867,\n",
              "          0.03444465, -0.01941529],\n",
              "        [ 0.00819464,  0.02885117, -0.01265359, ...,  0.03661799,\n",
              "         -0.02985857, -0.00824675],\n",
              "        ...,\n",
              "        [ 0.03466431, -0.0208142 ,  0.02533949, ..., -0.02378383,\n",
              "          0.03679091,  0.00116946],\n",
              "        [-0.01110245,  0.03692212,  0.01499962, ..., -0.00462792,\n",
              "          0.00192938,  0.02964102],\n",
              "        [-0.03204529,  0.01426597, -0.02421631, ..., -0.00780025,\n",
              "          0.01669463, -0.02586696]], dtype=float32)>,\n",
              " <tf.Variable 'encoder_dense2/bias:0' shape=(1000,) dtype=float32, numpy=\n",
              " array([ 1.87111949e-03, -3.54991294e-03, -6.00509532e-03, -6.00510323e-03,\n",
              "        -4.27376479e-03, -6.00511953e-03, -6.00513862e-03, -6.00500451e-03,\n",
              "        -2.17814057e-04,  2.41198787e-03, -5.55837434e-03,  0.00000000e+00,\n",
              "        -6.00511814e-03, -6.00513211e-03, -6.00462127e-03, -6.00495841e-03,\n",
              "        -3.27839842e-03, -6.00513583e-03,  0.00000000e+00,  2.86106253e-03,\n",
              "        -6.54255413e-03, -6.00511814e-03,  4.65389530e-05,  4.23424179e-03,\n",
              "        -3.61944037e-03,  5.78130782e-03, -6.00514002e-03, -8.09373334e-04,\n",
              "        -6.00511814e-03,  0.00000000e+00, -6.14948804e-03, -6.00512000e-03,\n",
              "        -4.25907038e-03, -3.29680950e-03, -1.64954487e-04,  0.00000000e+00,\n",
              "        -4.11916990e-03, -6.32976182e-03, -6.00512652e-03, -4.39495686e-03,\n",
              "        -6.00497192e-03, -6.00509439e-03, -6.00500964e-03, -6.00511208e-03,\n",
              "        -6.00499799e-03, -6.00511860e-03, -6.00513909e-03, -4.49258275e-03,\n",
              "        -6.00514282e-03,  1.09760612e-02,  0.00000000e+00, -6.56636013e-03,\n",
              "        -6.00511953e-03, -5.12564601e-03,  0.00000000e+00, -2.48627248e-03,\n",
              "        -3.64530110e-03,  4.43822611e-03,  1.24630763e-03, -5.55849774e-03,\n",
              "        -6.00510556e-03,  1.35779497e-03, -4.41794051e-03, -6.00514049e-03,\n",
              "         0.00000000e+00, -6.89506205e-03,  1.50337368e-02, -5.55849820e-03,\n",
              "        -6.00512326e-03, -4.37527709e-03,  8.69619753e-03, -4.33550356e-03,\n",
              "         0.00000000e+00,  2.25222274e-03, -5.11536235e-03, -3.03889019e-03,\n",
              "        -5.11251576e-03, -5.55849541e-03, -6.00511115e-03, -5.55849355e-03,\n",
              "        -5.56817418e-03, -6.00511115e-03, -6.00504130e-03, -6.00513397e-03,\n",
              "        -7.81803019e-03, -8.20871908e-04,  3.05658951e-03,  2.23093131e-03,\n",
              "        -6.00514049e-03, -6.00509765e-03, -5.11247711e-03, -5.55848284e-03,\n",
              "         9.14221816e-03, -2.64794799e-03, -1.46527760e-04, -7.09565211e-05,\n",
              "        -6.00511720e-03, -3.21284821e-03,  1.11113433e-02, -6.00513257e-03,\n",
              "        -4.39480226e-03, -6.00468880e-03, -6.00514328e-03, -3.30442074e-03,\n",
              "        -4.23153909e-03,  0.00000000e+00, -6.01005228e-03, -3.38061806e-03,\n",
              "        -4.33097593e-03, -3.18402681e-03, -5.22827823e-03, -6.00510230e-03,\n",
              "        -6.00498682e-03, -5.34661347e-03,  0.00000000e+00, -8.98769416e-04,\n",
              "        -6.00509206e-03,  9.41616576e-03, -1.26764900e-03, -6.00513769e-03,\n",
              "        -6.00501942e-03, -6.00513769e-03,  3.71044327e-04, -3.30418046e-03,\n",
              "        -6.00510789e-03, -6.00509532e-03, -6.00508787e-03, -6.56672893e-03,\n",
              "        -4.39167256e-03, -6.00511814e-03, -6.00510836e-03,  4.37074254e-04,\n",
              "        -3.87900136e-03, -4.06272942e-03, -6.00490766e-03, -4.41817893e-03,\n",
              "        -6.74372260e-03, -6.00514514e-03, -6.00510929e-03, -6.00513676e-03,\n",
              "        -3.03028990e-03, -5.22827404e-03, -4.08317707e-03, -6.00510929e-03,\n",
              "        -6.00514375e-03, -6.00492256e-03,  7.38343224e-05, -5.55849681e-03,\n",
              "        -1.64719019e-03, -6.10698620e-03, -6.00447506e-03, -6.00513956e-03,\n",
              "         0.00000000e+00, -6.00512419e-03, -1.30585558e-03, -6.00084197e-03,\n",
              "        -6.00512186e-03, -6.00510556e-03, -6.00509671e-03, -4.12399275e-03,\n",
              "        -4.54490352e-03, -5.34661626e-03,  6.00464595e-03, -6.00513117e-03,\n",
              "        -6.00514142e-03, -4.37775534e-03, -5.55849681e-03, -4.39336523e-03,\n",
              "        -4.38162033e-03, -4.53002797e-03, -4.11693798e-03,  1.01544149e-02,\n",
              "         7.71384174e-03, -6.00512326e-03, -4.37565334e-03, -5.31390728e-03,\n",
              "         6.00478519e-03, -6.00513211e-03,  0.00000000e+00, -6.00514142e-03,\n",
              "        -5.11477375e-03, -6.63486263e-03, -6.00513862e-03, -4.49167145e-03,\n",
              "         3.08667659e-03, -6.00514049e-03, -6.00513583e-03, -3.73762683e-03,\n",
              "        -6.10060664e-03,  3.48935509e-03, -4.27727122e-03, -2.31803209e-03,\n",
              "        -6.00488437e-03, -6.62329607e-03, -6.00504130e-03, -2.69098673e-03,\n",
              "        -6.00513397e-03, -6.04545092e-03, -4.93375724e-03, -6.00513816e-03,\n",
              "        -5.12543414e-03, -6.92320941e-03, -6.25574170e-03,  0.00000000e+00,\n",
              "        -6.00499008e-03, -6.00512512e-03, -7.41056108e-04,  0.00000000e+00,\n",
              "        -6.00504829e-03, -6.00513862e-03, -4.45148442e-03, -5.34661347e-03,\n",
              "         5.16070705e-03, -3.45948781e-03, -6.74575754e-03, -6.00494957e-03,\n",
              "         8.88835359e-03, -4.50795889e-03, -6.00513723e-03, -6.00503944e-03,\n",
              "        -6.00513583e-03,  5.98551380e-03, -6.00510044e-03, -6.00513536e-03,\n",
              "        -6.56800950e-03, -6.00508833e-03,  3.58882057e-03, -6.00508507e-03,\n",
              "         1.36879948e-03, -4.51599341e-03,  6.98013650e-03, -6.69752527e-03,\n",
              "        -4.51636687e-03, -7.08376430e-03,  5.52496128e-03, -6.00484759e-03,\n",
              "         3.45932576e-03,  6.00469112e-03,  2.10762009e-04,  1.14757137e-03,\n",
              "        -6.00441312e-03,  0.00000000e+00, -5.56785497e-04, -6.00514235e-03,\n",
              "        -4.34237393e-03, -3.95488366e-03, -4.37342515e-03, -4.55701584e-03,\n",
              "        -5.55849774e-03,  1.55619793e-02, -6.00514142e-03, -6.50183856e-03,\n",
              "        -6.00513723e-03, -5.35032712e-03, -2.98562663e-04, -6.00512652e-03,\n",
              "        -4.27482324e-03,  1.09900134e-02, -6.00509485e-03, -5.55849494e-03,\n",
              "        -6.00511627e-03, -6.00261288e-03, -7.61927757e-03, -6.00514095e-03,\n",
              "        -6.00490440e-03,  2.26144725e-03,  9.50892363e-03, -4.52801120e-03,\n",
              "        -6.00512326e-03, -6.00399543e-03,  1.18340191e-04, -3.95483151e-03,\n",
              "        -5.95739856e-03, -6.00514747e-03, -6.00513816e-03, -1.44795736e-03,\n",
              "        -6.00513816e-03, -6.00478379e-03, -4.49677510e-03,  6.95298426e-03,\n",
              "        -2.62123486e-03, -3.12618539e-03, -6.00403454e-03, -4.27333667e-04,\n",
              "        -5.34661952e-03, -4.39566793e-03, -5.55849401e-03, -6.00511627e-03,\n",
              "        -6.00512605e-03,  0.00000000e+00, -6.00513211e-03, -6.00514608e-03,\n",
              "        -6.00502174e-03,  6.21901650e-04,  4.24196199e-03, -6.00512838e-03,\n",
              "        -6.00503944e-03, -3.94513225e-03, -5.55849681e-03, -6.00511115e-03,\n",
              "        -4.11518198e-03,  2.24645832e-03, -6.00514608e-03, -6.00510463e-03,\n",
              "        -6.00512465e-03,  0.00000000e+00,  9.90781095e-03, -6.00506645e-03,\n",
              "         1.33053437e-02, -6.00504735e-03, -5.14103612e-03, -6.00497611e-03,\n",
              "         4.52280277e-03, -6.00511814e-03,  0.00000000e+00, -7.59036839e-03,\n",
              "        -6.78439904e-03, -5.22814551e-03,  5.34658786e-03, -1.78977230e-03,\n",
              "        -4.20038588e-03, -6.00511534e-03,  2.35581445e-03, -4.01308667e-03,\n",
              "        -4.24918905e-03,  9.04569961e-03, -6.00503199e-03, -4.57467884e-03,\n",
              "        -4.26213862e-03, -6.00505061e-03, -5.63019363e-04, -6.00512885e-03,\n",
              "         6.97281538e-03, -6.00514375e-03, -4.66306414e-03, -7.07126549e-03,\n",
              "        -6.00514794e-03, -4.51363577e-03, -7.48778833e-03, -6.00513909e-03,\n",
              "         1.56324636e-03, -5.22545073e-04, -6.00510603e-03, -6.00502361e-03,\n",
              "         0.00000000e+00,  1.11015062e-04,  6.88540749e-03,  0.00000000e+00,\n",
              "        -6.00511953e-03, -5.55849820e-03, -6.00514095e-03, -6.00509625e-03,\n",
              "         7.36404303e-03,  0.00000000e+00, -5.55849308e-03, -5.55849774e-03,\n",
              "        -1.62135274e-03, -5.34661440e-03, -6.00461522e-03, -6.00512326e-03,\n",
              "         0.00000000e+00, -6.00508600e-03, -6.00507297e-03,  0.00000000e+00,\n",
              "         5.30322595e-03, -6.00514282e-03, -6.00509625e-03, -4.53790743e-03,\n",
              "        -5.22827962e-03, -4.85584285e-04,  3.67126032e-03, -5.22816088e-03,\n",
              "        -6.00513117e-03, -6.00128109e-03, -6.00513350e-03, -6.00513769e-03,\n",
              "        -4.45135031e-03, -6.00506691e-03, -6.58445526e-03,  0.00000000e+00,\n",
              "        -6.00513304e-03, -6.00513490e-03, -4.48575849e-03, -6.00512559e-03,\n",
              "        -6.00496866e-03, -1.06561859e-03,  9.56228119e-04,  3.15371179e-03,\n",
              "        -6.00512465e-03,  1.49805974e-02, -6.00512559e-03, -6.00508228e-03,\n",
              "        -5.00961789e-04,  5.34483837e-03, -6.00509811e-03, -4.27153474e-03,\n",
              "        -6.00498263e-03, -5.55849401e-03, -6.00437727e-03, -3.71980830e-04,\n",
              "        -6.00512279e-03,  0.00000000e+00, -4.41704132e-03,  0.00000000e+00,\n",
              "        -4.49750386e-03,  1.48319406e-03, -5.93100721e-03, -6.00512605e-03,\n",
              "         0.00000000e+00, -3.30907083e-03, -6.62992056e-03, -6.00513536e-03,\n",
              "        -6.48542307e-03,  0.00000000e+00,  3.94152012e-03, -5.34661813e-03,\n",
              "        -6.00501476e-03, -6.34865323e-03, -6.00513583e-03, -5.55849588e-03,\n",
              "        -3.46858008e-03, -4.25005285e-03,  1.91475637e-03,  0.00000000e+00,\n",
              "        -6.00513956e-03, -6.00514235e-03, -6.00507390e-03,  0.00000000e+00,\n",
              "        -6.00510417e-03, -4.51668305e-03, -6.00514608e-03, -6.00514561e-03,\n",
              "        -6.74068136e-03,  0.00000000e+00, -6.00514654e-03, -5.34661813e-03,\n",
              "        -6.00509392e-03, -9.22083855e-04,  2.01242813e-03, -6.00514701e-03,\n",
              "        -1.49188004e-03, -6.00491371e-03, -7.52671249e-03, -6.00514142e-03,\n",
              "        -6.00481965e-03, -2.86046648e-03, -5.34661906e-03, -6.00495050e-03,\n",
              "        -6.00506039e-03, -5.34661906e-03, -6.00514188e-03, -4.52715484e-03,\n",
              "        -5.87835442e-03, -6.00510323e-03, -4.52625612e-03,  4.58814815e-04,\n",
              "         0.00000000e+00, -5.55849541e-03, -6.00514235e-03, -4.55315877e-03,\n",
              "        -6.00501895e-03, -6.00497797e-03, -6.00514328e-03, -6.78611128e-03,\n",
              "        -6.00510836e-03, -5.16091520e-03, -6.00507436e-03, -4.46689781e-03,\n",
              "        -6.00512791e-03,  3.42092128e-03, -6.00512139e-03, -5.16091660e-03,\n",
              "        -5.12744952e-03, -6.00513676e-03, -5.24931494e-03, -6.00501103e-03,\n",
              "        -6.00505713e-03, -6.00514049e-03, -6.00507949e-03, -4.54503857e-03,\n",
              "        -7.66243786e-04, -6.00513956e-03, -4.64489218e-03, -6.00509439e-03,\n",
              "        -6.89690886e-03, -6.00511627e-03, -5.22826333e-03, -8.83766543e-03,\n",
              "        -2.48992350e-03, -6.00514514e-03, -4.48166439e-03, -5.55849820e-03,\n",
              "        -1.82730297e-03, -6.00513257e-03,  0.00000000e+00, -5.22826472e-03,\n",
              "        -5.34661952e-03, -4.38648369e-03, -6.00513630e-03, -7.96156935e-04,\n",
              "        -6.00508833e-03, -6.00500545e-03,  0.00000000e+00, -6.00512419e-03,\n",
              "        -4.53746971e-03,  9.60569450e-05, -4.15674085e-03, -6.00512139e-03,\n",
              "         1.15253832e-02, -5.55849494e-03, -6.00478519e-03, -6.00512559e-03,\n",
              "         6.60951994e-03, -1.88241131e-03, -3.92934401e-03, -2.54646526e-03,\n",
              "        -6.00514142e-03, -5.34661673e-03, -3.13804438e-03, -3.54093337e-03,\n",
              "        -6.00514095e-03,  0.00000000e+00, -6.00509718e-03, -2.58922344e-03,\n",
              "        -2.42708367e-03, -3.47944070e-03, -1.07350736e-03, -6.00509159e-03,\n",
              "        -6.00512698e-03,  7.54533289e-03,  1.15611777e-02, -6.00513816e-03,\n",
              "         2.39201915e-03, -6.00514002e-03, -6.00508787e-03, -6.00324664e-03,\n",
              "        -6.00505061e-03, -5.55849634e-03, -6.00512652e-03,  0.00000000e+00,\n",
              "        -3.83712747e-03, -6.00504596e-03,  0.00000000e+00, -6.00486854e-03,\n",
              "        -1.62616046e-03,  0.00000000e+00, -2.02129968e-03,  9.23492573e-03,\n",
              "         5.72318328e-04, -4.51641111e-03,  1.42570934e-03,  0.00000000e+00,\n",
              "        -6.00514701e-03,  0.00000000e+00,  4.22891229e-03, -6.00505341e-03,\n",
              "        -1.47473789e-03, -4.40198602e-03,  0.00000000e+00, -6.00514561e-03,\n",
              "         0.00000000e+00, -6.00514328e-03,  0.00000000e+00,  1.11583201e-02,\n",
              "        -8.56610574e-03, -1.39734882e-03,  7.53645832e-03,  3.83742095e-04,\n",
              "         0.00000000e+00, -4.43658838e-03, -6.83146354e-05, -6.00512838e-03,\n",
              "        -4.27898299e-03, -5.22827869e-03, -6.00514142e-03, -7.80421542e-03,\n",
              "        -1.57576971e-04, -5.16091334e-03,  1.62622600e-03, -6.00512139e-03,\n",
              "        -6.00511441e-03, -4.00461536e-03, -6.00502733e-03,  1.09613054e-02,\n",
              "        -6.00501103e-03,  0.00000000e+00, -6.00509392e-03, -4.32643807e-03,\n",
              "         8.04692693e-03, -6.00513769e-03,  8.25836509e-03, -3.74393025e-03,\n",
              "        -5.55848749e-03, -6.00511907e-03, -4.55402676e-03, -4.48840298e-03,\n",
              "        -4.08892101e-03, -6.00505108e-03, -6.57384610e-03,  0.00000000e+00,\n",
              "         2.93574249e-03, -6.00509625e-03, -3.43002682e-03, -4.41983202e-03,\n",
              "        -5.99359535e-03, -4.84949531e-04, -6.64109271e-03, -6.00512139e-03,\n",
              "        -5.64396149e-03, -6.09534932e-03, -6.00506226e-03, -6.00510603e-03,\n",
              "        -4.25719516e-03, -6.00509625e-03,  5.85027225e-03, -3.14415153e-03,\n",
              "        -6.00404153e-03, -6.00497983e-03, -6.00514142e-03, -6.00489229e-03,\n",
              "         3.61708895e-04,  4.25629597e-03, -5.99546777e-03,  1.07896607e-02,\n",
              "        -6.83809351e-03,  0.00000000e+00, -6.00507902e-03, -4.27796738e-03,\n",
              "         6.00458868e-03, -3.83605552e-03, -4.52308683e-03, -6.00513630e-03,\n",
              "        -1.61302404e-03,  6.60022080e-04, -5.23214974e-03,  6.77564507e-03,\n",
              "        -5.55848936e-03,  1.44814816e-03, -4.26060893e-03,  3.45378299e-03,\n",
              "        -6.00511674e-03,  1.02090435e-02, -6.00478332e-03, -1.71620143e-03,\n",
              "        -5.55849541e-03, -4.16013971e-03, -6.00500638e-03,  2.69384636e-03,\n",
              "         0.00000000e+00, -6.00510836e-03, -6.00513630e-03,  0.00000000e+00,\n",
              "        -6.00505434e-03,  4.09693737e-03,  1.04217837e-03, -5.55849634e-03,\n",
              "         3.22563713e-03, -6.00512465e-03, -1.26018142e-03, -6.00512139e-03,\n",
              "        -7.48936692e-03,  3.68272210e-03,  6.47100108e-03, -8.71465169e-03,\n",
              "        -5.34658553e-03,  8.07895418e-03, -2.20850087e-03, -6.00396050e-03,\n",
              "         1.27459140e-02,  6.00501336e-03, -6.00513397e-03, -6.00512279e-03,\n",
              "         7.23112421e-03, -6.00426272e-03, -6.00497518e-03, -6.00514095e-03,\n",
              "        -8.78275430e-04, -6.00513117e-03, -5.34661999e-03, -6.00503199e-03,\n",
              "        -6.00507390e-03, -6.00501429e-03, -6.00513350e-03,  0.00000000e+00,\n",
              "         0.00000000e+00,  1.69619685e-03, -6.00511674e-03, -6.00513630e-03,\n",
              "        -5.12941694e-03, -6.00510556e-03,  0.00000000e+00,  1.78183184e-03,\n",
              "        -6.00513909e-03,  3.88272759e-03, -5.34658926e-03, -6.00514002e-03,\n",
              "        -6.22201059e-03, -6.00511814e-03, -4.25025960e-03, -6.00514328e-03,\n",
              "        -6.00511953e-03, -6.98149344e-03,  3.99662997e-04, -6.00493373e-03,\n",
              "         0.00000000e+00, -6.00510696e-03, -6.00503199e-03,  0.00000000e+00,\n",
              "        -6.00481732e-03, -6.00514561e-03, -2.34330888e-03, -6.00511068e-03,\n",
              "         1.47035848e-02, -6.00514328e-03,  0.00000000e+00, -6.00509439e-03,\n",
              "        -4.27188911e-03, -6.00455701e-03, -4.32284316e-03,  1.07695395e-03,\n",
              "         0.00000000e+00, -6.00511208e-03, -9.52264410e-04, -6.00506598e-03,\n",
              "         2.27613142e-03, -6.00480009e-03, -6.00511907e-03, -7.13758753e-04,\n",
              "        -4.55522258e-03, -6.00512465e-03, -1.31987373e-03, -5.55849448e-03,\n",
              "        -5.34660695e-03, -1.73148990e-04, -6.00514235e-03, -6.00514095e-03,\n",
              "        -4.32734424e-03, -4.51539317e-03, -6.21135440e-03,  0.00000000e+00,\n",
              "        -6.00513024e-03,  1.18122448e-03,  2.74658762e-03, -5.75274043e-03,\n",
              "        -5.34661952e-03, -5.22827310e-03,  1.26113591e-03,  0.00000000e+00,\n",
              "        -6.00514235e-03,  1.10224017e-03, -6.00510882e-03, -6.00511953e-03,\n",
              "        -6.00510649e-03, -6.00513117e-03, -6.00513630e-03, -4.51549282e-03,\n",
              "        -5.13225794e-03, -4.04444942e-03,  8.73725570e-04, -4.42314055e-03,\n",
              "        -6.00512139e-03,  3.21861985e-03, -6.00512465e-03, -6.00511581e-03,\n",
              "         1.65129721e-03, -1.40107668e-03, -4.10026824e-03, -6.00507483e-03,\n",
              "        -6.00514188e-03, -4.50084591e-03, -4.34409920e-03, -5.34661440e-03,\n",
              "        -6.00514142e-03,  5.59292780e-03, -6.56219758e-03, -4.35503433e-03,\n",
              "        -4.25609387e-03, -6.00502221e-03, -4.28237161e-03, -6.00471906e-03,\n",
              "        -4.16435068e-04, -6.00512791e-03, -4.53365734e-03, -2.43322435e-03,\n",
              "         4.29626275e-03, -6.00514002e-03, -6.20114291e-03,  0.00000000e+00,\n",
              "        -6.00514095e-03, -6.00513676e-03, -6.00503571e-03,  2.59404676e-03,\n",
              "         1.77088485e-03, -5.80114452e-03, -6.00508694e-03, -6.00514328e-03,\n",
              "         2.96533853e-03, -6.00512838e-03,  1.54030090e-03, -4.43586707e-03,\n",
              "        -6.00513117e-03,  0.00000000e+00,  2.14544032e-03, -4.59486060e-03,\n",
              "         1.44176437e-02, -4.18621162e-03,  1.58352032e-03, -8.52863211e-03,\n",
              "        -6.00514095e-03, -3.87737947e-03, -6.00384036e-03, -3.17812501e-03,\n",
              "        -5.55849355e-03, -2.92401901e-03, -3.76600027e-03, -6.00514002e-03,\n",
              "        -7.85913505e-03, -5.31280320e-03, -6.00513211e-03, -5.55849681e-03,\n",
              "        -6.00508461e-03, -5.11249155e-03, -6.00504735e-03, -6.00430276e-03,\n",
              "        -5.11537585e-03, -5.22827264e-03,  0.00000000e+00,  3.09048104e-04,\n",
              "        -6.95056398e-04, -6.00511488e-03, -6.49499334e-03, -3.36173922e-03,\n",
              "        -2.14987458e-03, -6.62937015e-03, -6.00512419e-03, -6.00482523e-03,\n",
              "        -5.34661673e-03, -4.71221237e-03, -6.00513630e-03, -6.59795618e-03,\n",
              "        -6.00513816e-03, -6.59679295e-03,  0.00000000e+00, -4.29192884e-03,\n",
              "        -6.00510743e-03, -6.00513304e-03, -6.62954617e-03,  1.00060739e-02,\n",
              "        -3.42205307e-03,  0.00000000e+00, -6.12642942e-03, -1.20076096e-04,\n",
              "        -6.00509951e-03, -7.65603967e-03, -6.00512559e-03, -3.49603454e-03,\n",
              "        -6.00514095e-03, -5.22827636e-03, -1.68679678e-03, -1.32023543e-03,\n",
              "        -6.00513304e-03, -5.09047508e-03, -6.00512791e-03, -1.01207453e-03,\n",
              "        -4.40114550e-03, -5.98723255e-03, -4.45414893e-03, -1.77302992e-03,\n",
              "         3.54536402e-04, -6.00509904e-03, -6.00508321e-03, -4.71313437e-03,\n",
              "         0.00000000e+00, -6.00467809e-03,  0.00000000e+00, -6.00512233e-03,\n",
              "        -1.99711300e-03, -5.55849355e-03, -3.57958605e-03, -1.80787430e-03,\n",
              "        -6.00512512e-03, -5.55849820e-03, -3.67651088e-03,  7.27151288e-03,\n",
              "         0.00000000e+00, -6.00509439e-03, -6.00512419e-03, -2.41760095e-03,\n",
              "        -2.26948969e-03,  0.00000000e+00, -5.22823771e-03,  0.00000000e+00,\n",
              "        -6.00507390e-03, -4.65767831e-03, -6.00492582e-03, -6.00505341e-03,\n",
              "        -6.00513024e-03, -5.21084759e-03, -6.00490673e-03, -4.52526333e-03,\n",
              "        -6.00509485e-03, -1.01932762e-02, -4.46586404e-03, -5.34661440e-03,\n",
              "        -6.00512139e-03, -6.00514049e-03, -2.00617360e-03, -6.00514095e-03,\n",
              "         2.97659542e-03, -4.07160167e-03,  1.37769831e-02,  9.16949566e-03,\n",
              "        -6.00509159e-03, -9.07244254e-03, -4.12311684e-03,  0.00000000e+00,\n",
              "        -5.55849401e-03, -5.55849820e-03, -4.22731601e-03,  4.80164250e-04,\n",
              "        -6.00510044e-03,  3.24902730e-03,  0.00000000e+00, -6.00428786e-03,\n",
              "        -5.67022944e-03,  5.23282727e-03,  1.39778331e-02, -6.49666646e-03,\n",
              "        -6.00511814e-03, -5.55849355e-03,  0.00000000e+00, -5.24740107e-03,\n",
              "         1.03269694e-02,  5.55845676e-03, -4.34784591e-03, -1.51227554e-03,\n",
              "        -6.00494910e-03,  1.04967994e-03, -6.00508554e-03,  7.26254948e-04,\n",
              "        -6.00434234e-03, -6.00512233e-03, -4.46765963e-03, -6.00503897e-03,\n",
              "         0.00000000e+00, -6.44313218e-03,  2.14540260e-03, -6.00512233e-03,\n",
              "        -5.34661533e-03, -4.10630787e-03, -4.24045138e-03, -6.00514421e-03,\n",
              "        -5.22827497e-03, -5.55849820e-03,  0.00000000e+00, -6.00506458e-03,\n",
              "        -1.90528401e-03,  0.00000000e+00, -6.00429578e-03, -6.00504270e-03,\n",
              "         0.00000000e+00, -4.46657091e-03, -6.00514701e-03, -7.05222832e-03,\n",
              "        -3.28193791e-03, -4.51312214e-03, -4.19562589e-03, -6.00508600e-03,\n",
              "         1.88908190e-03, -6.00504316e-03, -6.00511720e-03,  4.37234761e-03,\n",
              "        -6.00402988e-03, -5.55849681e-03, -3.11923423e-03, -4.49659163e-03,\n",
              "        -4.29742364e-03, -6.00514049e-03, -4.52647312e-03,  0.00000000e+00,\n",
              "         0.00000000e+00, -6.00514142e-03, -6.00509439e-03, -6.00514654e-03,\n",
              "         5.72358351e-03, -6.00501150e-03, -7.03117112e-03,  1.77909192e-02,\n",
              "        -5.55849401e-03, -6.00508926e-03, -4.49157227e-03, -6.00509858e-03,\n",
              "        -6.00513304e-03, -1.34870713e-03,  5.40181715e-03,  1.17261056e-02,\n",
              "        -1.68083061e-03, -4.47830372e-03,  4.83703893e-03, -6.00489276e-03],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'encoder_dense3/kernel:0' shape=(1000, 500) dtype=float32, numpy=\n",
              " array([[ 0.05192962,  0.04295347, -0.03372126, ..., -0.01713122,\n",
              "          0.02731117,  0.0302812 ],\n",
              "        [ 0.05234164,  0.00897845, -0.00597779, ..., -0.01211421,\n",
              "         -0.06309249,  0.0166479 ],\n",
              "        [ 0.00722413,  0.00874616,  0.0302231 , ..., -0.01569053,\n",
              "         -0.0496993 , -0.00956166],\n",
              "        ...,\n",
              "        [ 0.00239912, -0.00515739,  0.02595748, ...,  0.00161313,\n",
              "         -0.00923032,  0.00124973],\n",
              "        [ 0.01544442,  0.03036676,  0.01872298, ...,  0.03536168,\n",
              "          0.03635308, -0.04465185],\n",
              "        [-0.0341931 ,  0.02595694, -0.02386971, ..., -0.02667606,\n",
              "         -0.01831215, -0.04060356]], dtype=float32)>,\n",
              " <tf.Variable 'encoder_dense3/bias:0' shape=(500,) dtype=float32, numpy=\n",
              " array([-1.10666396e-03, -1.01280967e-02, -8.93770158e-03,  5.09431353e-03,\n",
              "        -8.02341942e-03, -5.55849867e-03, -6.00507902e-03, -6.00514561e-03,\n",
              "         5.77438856e-03, -4.28304635e-03, -6.00514142e-03,  0.00000000e+00,\n",
              "        -6.00514328e-03, -1.18688484e-04, -1.03630107e-02, -1.04669691e-03,\n",
              "        -6.00510743e-03, -9.63266473e-03, -3.65665182e-03, -2.67984834e-03,\n",
              "        -6.00514701e-03,  9.15474538e-03, -6.00514794e-03, -6.00513816e-03,\n",
              "        -4.32815542e-03, -5.55849867e-03, -6.00514887e-03, -4.52046888e-03,\n",
              "        -5.84759004e-03,  0.00000000e+00,  9.04347003e-03, -5.34661952e-03,\n",
              "         0.00000000e+00,  4.43275552e-03,  1.06971469e-02,  0.00000000e+00,\n",
              "        -5.85172838e-03, -9.15411394e-03, -6.00512885e-03,  0.00000000e+00,\n",
              "        -5.05450321e-03, -4.43789316e-03, -6.00514002e-03, -6.00514328e-03,\n",
              "        -6.00514002e-03, -6.10685069e-03, -1.41603546e-03, -4.05055191e-03,\n",
              "        -5.90593694e-03, -3.24889715e-03,  9.32412455e-04, -9.53026349e-04,\n",
              "        -6.00514887e-03,  1.55501161e-03, -6.00514282e-03,  2.47480022e-03,\n",
              "         1.01379650e-02,  5.55386906e-03,  2.40820504e-04, -6.00513769e-03,\n",
              "        -3.65531910e-03, -7.13145640e-03, -2.52123666e-03,  7.43143959e-03,\n",
              "         0.00000000e+00, -6.00512698e-03, -5.22627076e-03, -2.58969003e-03,\n",
              "         3.23641021e-03, -6.00512326e-03, -6.00484526e-03, -3.17828450e-03,\n",
              "         4.81556030e-03, -7.28886249e-03, -6.00514561e-03, -6.78618555e-04,\n",
              "        -9.67423245e-03, -6.00514095e-03, -6.86515402e-03, -6.00513862e-03,\n",
              "        -6.00513024e-03, -1.19047854e-02, -9.93451290e-03, -3.00010992e-03,\n",
              "        -5.55849867e-03, -5.11249760e-03, -3.44259525e-03, -1.21682191e-04,\n",
              "        -5.34661999e-03, -6.00513490e-03,  5.80289541e-03, -5.55849867e-03,\n",
              "        -6.96858624e-03, -6.00511814e-03, -5.15472796e-03, -8.67330562e-03,\n",
              "        -4.10455139e-03,  7.59846438e-03, -5.34661626e-03, -1.31544401e-03,\n",
              "         9.20449290e-03,  4.00082953e-03, -5.52044890e-04, -4.21837159e-03,\n",
              "        -1.13333412e-03, -5.17078117e-03,  6.00835634e-03, -6.00514887e-03,\n",
              "        -7.57690985e-03,  9.59702709e-04, -6.00514701e-03, -6.58464385e-03,\n",
              "        -5.55849774e-03,  0.00000000e+00,  7.20619166e-04, -8.75022542e-03,\n",
              "        -7.10615469e-03,  5.35536651e-03, -6.23835437e-03, -1.01957824e-02,\n",
              "        -7.73537206e-03, -6.00514514e-03, -6.25995221e-03,  6.38434291e-03,\n",
              "         0.00000000e+00,  1.70949241e-03, -4.29862039e-03, -8.18832591e-03,\n",
              "        -6.00512279e-03, -4.63700108e-03,  6.95964275e-03,  3.34913144e-03,\n",
              "         4.33458667e-03, -6.63815718e-03, -4.54446860e-03, -4.26204829e-03,\n",
              "        -7.32500292e-03,  4.46223858e-04, -5.34661999e-03, -6.00508600e-03,\n",
              "         1.68816745e-03, -9.03165527e-03, -5.34661999e-03, -8.53500050e-03,\n",
              "        -5.70564123e-04,  2.73015187e-03, -8.19554646e-03,  7.49028707e-03,\n",
              "        -6.03475887e-03, -6.00346411e-03, -6.00511115e-03, -6.00514608e-03,\n",
              "        -2.75795977e-03,  0.00000000e+00, -6.00514002e-03, -9.17369034e-03,\n",
              "        -3.60140530e-03, -6.00716099e-03, -4.39334475e-03, -6.00514235e-03,\n",
              "        -6.22408697e-03, -8.96723568e-03, -5.32103935e-04, -5.34661580e-03,\n",
              "        -6.92796940e-03,  0.00000000e+00,  2.51708925e-03, -5.55849774e-03,\n",
              "        -7.94339739e-03,  1.17602926e-02, -4.16381611e-03, -7.17085972e-03,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.33459005e-04, -6.00513397e-03,\n",
              "         1.03050284e-02,  9.23948642e-03,  6.25431631e-03, -3.91820539e-03,\n",
              "        -6.00514188e-03,  1.05840694e-02, -9.04618483e-03, -6.00514794e-03,\n",
              "        -6.98854821e-03, -5.55849401e-03, -3.39700165e-03,  6.02673972e-03,\n",
              "         1.08892785e-03, -7.67751015e-04, -6.60705986e-03, -6.00514747e-03,\n",
              "        -4.16081399e-03, -6.00509532e-03, -2.37310166e-03, -6.00511208e-03,\n",
              "        -6.00514561e-03, -6.00512279e-03, -6.60944311e-03, -6.00510417e-03,\n",
              "        -6.00511441e-03, -6.00382965e-03, -4.51821461e-03, -6.43581012e-03,\n",
              "         0.00000000e+00, -1.05107520e-02, -7.87491910e-03, -6.00514794e-03,\n",
              "        -6.62199548e-03, -5.70631353e-03, -1.32398808e-03, -6.00513211e-03,\n",
              "        -6.00507855e-03,  6.00511488e-03, -7.85461813e-03, -9.66156367e-03,\n",
              "        -1.14198576e-03,  7.16557400e-03, -9.18343198e-03, -3.50840040e-03,\n",
              "         1.09553207e-02,  1.74670573e-02, -2.79687694e-03,  4.59942617e-04,\n",
              "        -5.11251716e-03, -1.08166307e-03, -5.22827590e-03,  1.99244893e-03,\n",
              "        -2.46163108e-03, -6.00514701e-03,  1.20843267e-02,  1.14354817e-02,\n",
              "        -6.00513909e-03, -1.66505808e-03,  0.00000000e+00,  4.55599802e-04,\n",
              "         1.30708748e-03,  3.51757486e-03,  3.21347179e-04, -3.52919265e-03,\n",
              "         1.06592048e-02, -4.37736837e-03, -1.05762519e-02, -5.03012212e-03,\n",
              "        -5.55849727e-03,  9.21614654e-03, -4.65647271e-03, -5.15670469e-03,\n",
              "        -1.06269345e-02,  6.37674704e-04,  3.15316999e-03, -6.00514095e-03,\n",
              "        -7.57248793e-03, -8.00220668e-03, -2.01543653e-03, -6.00514421e-03,\n",
              "        -5.34661859e-03, -3.41492798e-03,  1.96759403e-03,  3.79975908e-03,\n",
              "        -5.55375265e-03, -7.31697772e-03,  6.00510696e-03,  8.60275992e-04,\n",
              "        -6.00512279e-03, -3.57669848e-03, -6.58360310e-03, -1.00584142e-02,\n",
              "         3.09485302e-04,  2.16068653e-03,  5.16515225e-03, -5.55849727e-03,\n",
              "        -1.52889383e-03,  2.13309744e-04, -6.00514514e-03, -6.00514049e-03,\n",
              "        -9.70361196e-03, -6.00430602e-03,  0.00000000e+00, -2.25414382e-03,\n",
              "         0.00000000e+00, -3.39992042e-03, -1.28383534e-02, -6.00513769e-03,\n",
              "        -6.00514654e-03, -4.43779444e-03, -6.00509997e-03, -5.55849867e-03,\n",
              "        -5.46796434e-03, -5.55849867e-03,  7.78645277e-03,  6.39266707e-03,\n",
              "         0.00000000e+00, -3.89607949e-03, -5.22827357e-03,  8.16066097e-03,\n",
              "        -4.54170257e-03,  0.00000000e+00,  5.97925391e-04, -6.00514794e-03,\n",
              "        -3.17829102e-03, -4.39020107e-03, -4.45362926e-03,  0.00000000e+00,\n",
              "         6.20822376e-03, -5.46063820e-04,  0.00000000e+00, -7.67376879e-03,\n",
              "        -4.22070967e-03, -5.40766958e-03, -7.62439985e-03,  4.41948185e-03,\n",
              "         1.29601900e-02,  0.00000000e+00,  0.00000000e+00, -6.00514840e-03,\n",
              "        -5.22827916e-03,  7.47584226e-03,  2.21779337e-03, -5.55849867e-03,\n",
              "        -9.01576877e-03, -6.56577293e-03,  7.44565297e-03,  6.31189812e-03,\n",
              "        -7.68568320e-03, -1.41414790e-03,  6.27118628e-03, -4.44182847e-03,\n",
              "        -4.62840497e-03,  0.00000000e+00, -3.67376232e-03,  0.00000000e+00,\n",
              "        -4.49546287e-03, -1.24661513e-02, -6.00514375e-03, -6.47908892e-04,\n",
              "         1.59829506e-04, -4.42633685e-03, -6.00514468e-03,  0.00000000e+00,\n",
              "        -4.56452975e-03,  5.59474947e-03, -6.00514794e-03,  4.00636951e-03,\n",
              "        -2.20791926e-03,  5.67645114e-03, -5.38585987e-03, -6.00514747e-03,\n",
              "        -6.00509252e-03, -4.37874859e-03, -5.89261297e-03, -6.00511394e-03,\n",
              "         0.00000000e+00, -6.00453326e-03, -3.62535939e-03, -5.83436619e-03,\n",
              "        -9.67081287e-04,  8.67541621e-06,  6.00447785e-03, -6.00514142e-03,\n",
              "        -4.50091623e-03, -4.08954313e-03,  4.22426639e-03, -2.67636287e-03,\n",
              "        -5.55849820e-03, -7.44788861e-03,  2.04389612e-03,  6.36706315e-03,\n",
              "        -3.88725591e-03, -6.00508414e-03,  0.00000000e+00, -5.13447169e-03,\n",
              "        -3.10164667e-03,  0.00000000e+00, -3.71287670e-03, -5.46271913e-03,\n",
              "        -6.00514002e-03, -4.38137585e-03, -6.00514002e-03,  9.84346122e-03,\n",
              "        -6.00514095e-03,  7.52729713e-04,  5.32750040e-03, -1.12996320e-04,\n",
              "         6.00509346e-03, -9.96882882e-05, -6.00514421e-03,  5.16526215e-03,\n",
              "        -6.00513909e-03, -5.55849820e-03,  6.44815154e-03, -3.10476590e-03,\n",
              "        -7.20891310e-03, -2.84207310e-03, -3.66413128e-03, -6.00512093e-03,\n",
              "        -6.00514002e-03, -3.39908991e-03, -1.78780593e-03,  9.21293814e-03,\n",
              "        -5.07647125e-03, -6.00514282e-03, -3.87644535e-03, -6.00513024e-03,\n",
              "        -6.00506458e-03, -6.00513583e-03,  3.10302246e-03, -1.34591281e-03,\n",
              "        -4.44303034e-03, -2.84396159e-03, -1.57661922e-03, -6.94180746e-03,\n",
              "        -6.00513769e-03, -7.41346786e-03, -2.10958789e-03, -6.00514887e-03,\n",
              "        -6.08227588e-03, -4.33980534e-03, -6.00507157e-03, -6.49555400e-03,\n",
              "        -6.63977349e-03, -7.51705375e-03, -5.31441066e-03, -5.39715961e-03,\n",
              "        -6.00500405e-03,  8.42658617e-03, -6.75393594e-03, -6.89542294e-03,\n",
              "        -6.59423461e-03, -4.81529906e-03, -5.47718024e-03,  1.22672375e-02,\n",
              "        -7.04774400e-03, -2.53438996e-03, -8.91169999e-03,  6.00512791e-03,\n",
              "        -3.42934788e-03,  1.80742843e-03, -4.37229872e-03, -6.00514608e-03,\n",
              "        -6.35366980e-03, -6.00514095e-03, -6.00511441e-03,  0.00000000e+00,\n",
              "         6.33133575e-03, -6.00514188e-03, -8.88760947e-03, -6.00514514e-03,\n",
              "        -5.55849774e-03, -1.99712347e-03, -7.06677837e-03, -4.44898894e-03,\n",
              "        -6.00455422e-03,  7.48368260e-03, -7.65935378e-03, -6.00504735e-03,\n",
              "         5.64707350e-03, -6.00513676e-03, -5.22827869e-03, -4.57142387e-03,\n",
              "        -6.00512931e-03, -2.84709502e-03,  6.00318797e-03, -4.32374375e-03,\n",
              "         3.12006287e-03,  1.18921825e-03, -6.86562713e-03,  0.00000000e+00,\n",
              "        -1.09284958e-02, -7.99943786e-03, -6.00508880e-03, -6.51224516e-03,\n",
              "        -6.79491647e-03, -6.67694025e-03,  5.04700514e-03, -5.85952494e-03,\n",
              "        -5.24273422e-03, -3.21371132e-03,  0.00000000e+00, -6.00488205e-03,\n",
              "         1.00805722e-02, -3.61937494e-03,  1.07833641e-02, -6.00500405e-03,\n",
              "        -2.79955729e-03, -6.00514514e-03, -1.04033854e-02,  5.45032369e-03,\n",
              "         7.54099665e-03,  5.80164930e-03, -6.00513909e-03, -3.94801697e-04,\n",
              "        -2.06957757e-03, -4.53837588e-03, -6.00514794e-03,  8.80127947e-04,\n",
              "         3.18571273e-03, -6.00507949e-03, -5.55849774e-03, -2.74888519e-03],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'encoder_dense4/kernel:0' shape=(500, 152) dtype=float32, numpy=\n",
              " array([[ 0.05694213, -0.05616412,  0.00099094, ...,  0.04152123,\n",
              "          0.00070868,  0.00305366],\n",
              "        [-0.0119082 , -0.03048383, -0.07738754, ..., -0.017046  ,\n",
              "          0.07134062,  0.0323971 ],\n",
              "        [ 0.00396097, -0.08515505,  0.07087405, ..., -0.09008124,\n",
              "          0.05151986, -0.00634459],\n",
              "        ...,\n",
              "        [-0.04089822,  0.00879161,  0.02315234, ..., -0.09173383,\n",
              "          0.0946059 ,  0.02361914],\n",
              "        [ 0.04266364,  0.03336225, -0.04233616, ...,  0.09227494,\n",
              "          0.02680311, -0.08534296],\n",
              "        [ 0.02434379, -0.05148374,  0.03818041, ...,  0.09296008,\n",
              "          0.00566596, -0.0698001 ]], dtype=float32)>,\n",
              " <tf.Variable 'encoder_dense4/bias:0' shape=(152,) dtype=float32, numpy=\n",
              " array([-0.0055585 , -0.0059714 , -0.00848772, -0.00723323, -0.00600514,\n",
              "        -0.00821093, -0.00800976, -0.00979974, -0.00600514, -0.00621342,\n",
              "        -0.00767251, -0.006162  , -0.01004657, -0.00794885, -0.01094335,\n",
              "        -0.00753273, -0.00738285, -0.00809905, -0.00600515, -0.00447967,\n",
              "        -0.00687129,  0.        , -0.01127771, -0.0062219 , -0.00600515,\n",
              "        -0.0055585 , -0.00600512, -0.00600513, -0.00643212, -0.0049366 ,\n",
              "        -0.0068027 , -0.00576096, -0.00297651, -0.00652121, -0.00724533,\n",
              "        -0.00541283, -0.00690714, -0.01020529, -0.00949299, -0.00152125,\n",
              "        -0.00600515,  0.        , -0.01010889, -0.01700647, -0.00600515,\n",
              "         0.        , -0.00600483, -0.00888791, -0.01281282, -0.00990597,\n",
              "        -0.00600514, -0.00444626, -0.00251602, -0.00675587, -0.01936017,\n",
              "        -0.00907297, -0.00638907,  0.        , -0.00942281, -0.00906198,\n",
              "        -0.01081484, -0.0051593 , -0.007636  , -0.00541146, -0.00882147,\n",
              "        -0.0055585 ,  0.        , -0.00121046, -0.01275191, -0.00714912,\n",
              "        -0.00138551,  0.00584286, -0.00934074, -0.00767238,  0.00522828,\n",
              "        -0.00685322, -0.00522828, -0.00671911, -0.00900781, -0.00453446,\n",
              "        -0.00534662, -0.00164228, -0.00600514, -0.00974371, -0.00741295,\n",
              "        -0.00600515, -0.00912313, -0.00600513, -0.00725702, -0.00731406,\n",
              "        -0.00890921, -0.00869825, -0.00708321, -0.00565377, -0.00337257,\n",
              "        -0.00600209, -0.00667827, -0.00600515, -0.00748959, -0.00821165,\n",
              "        -0.00447851, -0.01452856, -0.0074279 ,  0.        ,  0.        ,\n",
              "        -0.00585484, -0.00452275, -0.00872412, -0.0055585 , -0.00818847,\n",
              "        -0.00600515, -0.00600515, -0.00600509, -0.00534662, -0.00083535,\n",
              "        -0.00737126, -0.00565477, -0.00983667,  0.        , -0.00600515,\n",
              "        -0.0055585 , -0.00382884, -0.01323207, -0.00598471, -0.00596279,\n",
              "        -0.00948111, -0.01367287, -0.00591817, -0.00912816,  0.        ,\n",
              "        -0.00772294, -0.00847118, -0.00600514, -0.00511252, -0.00824104,\n",
              "        -0.00548743, -0.01290333, -0.00675107, -0.00534662, -0.00845286,\n",
              "        -0.01288954, -0.00641234, -0.00600506,  0.00600276, -0.00842141,\n",
              "        -0.00600515,  0.        ,  0.        , -0.00600511,  0.        ,\n",
              "        -0.00989457, -0.00702559], dtype=float32)>,\n",
              " <tf.Variable 'dense/kernel:0' shape=(16, 500) dtype=float32, numpy=\n",
              " array([[-0.00192429,  0.04630131, -0.00515082, ..., -0.06574158,\n",
              "          0.09657736,  0.04028651],\n",
              "        [ 0.0667737 ,  0.10687497,  0.0844281 , ..., -0.05400927,\n",
              "          0.04129544,  0.02695289],\n",
              "        [ 0.09517026,  0.04914355, -0.01371161, ..., -0.04585679,\n",
              "         -0.05163509,  0.07797891],\n",
              "        ...,\n",
              "        [-0.00579213, -0.07984014,  0.02760883, ...,  0.0513543 ,\n",
              "          0.07308331, -0.07281496],\n",
              "        [ 0.10442127, -0.1069802 ,  0.02544425, ...,  0.06504542,\n",
              "          0.03781584,  0.08307721],\n",
              "        [ 0.07906097, -0.0064078 ,  0.05682437, ...,  0.02615306,\n",
              "         -0.01467582,  0.01860198]], dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(500,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/kernel:0' shape=(500, 1000) dtype=float32, numpy=\n",
              " array([[ 0.00165209, -0.03561777, -0.03613458, ...,  0.03957978,\n",
              "         -0.05377747,  0.00833993],\n",
              "        [ 0.06252365, -0.04058493, -0.00472091, ...,  0.0266686 ,\n",
              "         -0.03577761,  0.05483522],\n",
              "        [-0.05945161,  0.02250014,  0.04917409, ...,  0.04231483,\n",
              "          0.044278  , -0.0314994 ],\n",
              "        ...,\n",
              "        [ 0.00546541, -0.00903049,  0.01921319, ...,  0.04967552,\n",
              "         -0.04183099, -0.0450785 ],\n",
              "        [ 0.0457682 , -0.05216743, -0.0429263 , ...,  0.02574367,\n",
              "         -0.05563471, -0.02794176],\n",
              "        [-0.05115294, -0.04998126, -0.00933472, ...,  0.01188336,\n",
              "         -0.02896433, -0.05331845]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(1000,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_2/kernel:0' shape=(1000, 5000) dtype=float32, numpy=\n",
              " array([[ 0.026041  ,  0.01579792,  0.00371647, ..., -0.00626785,\n",
              "          0.0281608 , -0.0009578 ],\n",
              "        [-0.02112172, -0.00964895,  0.0100517 , ..., -0.01384208,\n",
              "         -0.0105214 ,  0.01600101],\n",
              "        [ 0.00195887, -0.00068752,  0.008545  , ..., -0.01641702,\n",
              "          0.01516474,  0.00986115],\n",
              "        ...,\n",
              "        [ 0.03092135, -0.02950111,  0.00059662, ..., -0.02726096,\n",
              "         -0.02000018, -0.01778892],\n",
              "        [-0.01567569,  0.01139348,  0.02081981, ..., -0.02985909,\n",
              "         -0.03067716, -0.01619793],\n",
              "        [-0.00284121,  0.01336514,  0.00220608, ...,  0.02417051,\n",
              "         -0.01278851,  0.02741877]], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(5000,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/kernel:0' shape=(5000, 10000) dtype=float32, numpy=\n",
              " array([[ 0.01463269, -0.00164428, -0.0189827 , ...,  0.01890001,\n",
              "          0.0030232 , -0.00341084],\n",
              "        [-0.00218009,  0.01707482,  0.00909172, ..., -0.00111341,\n",
              "         -0.00815354, -0.01577985],\n",
              "        [ 0.00218032,  0.00094054,  0.00316456, ..., -0.01173166,\n",
              "          0.0090285 ,  0.01989237],\n",
              "        ...,\n",
              "        [ 0.00600406,  0.00433721, -0.01492113, ..., -0.01480063,\n",
              "         -0.01614355,  0.00288   ],\n",
              "        [-0.00776126, -0.00415913,  0.01256684, ..., -0.00053485,\n",
              "          0.01853785,  0.00339849],\n",
              "        [ 0.01961558, -0.01700104, -0.01559662, ...,  0.01965399,\n",
              "         -0.01949739, -0.01213638]], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/bias:0' shape=(10000,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OPYejWiC2ftf",
        "outputId": "eb34be96-2f99-41e2-e881-18ecf72ae804"
      },
      "source": [
        "\n",
        "hist = model.fit(train, epochs=15, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='tfpvae')] , validation_data=test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 1/18 [>.............................] - ETA: 14s - loss: 3.1532WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 2/18 [==>...........................] - ETA: 8s - loss: 3.3438 WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 3/18 [====>.........................] - ETA: 8s - loss: 3.5217WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 4/18 [=====>........................] - ETA: 7s - loss: 3.6127WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 5/18 [=======>......................] - ETA: 6s - loss: 3.6386WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 6/18 [=========>....................] - ETA: 6s - loss: 3.6461WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 7/18 [==========>...................] - ETA: 5s - loss: 3.6347WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 8/18 [============>.................] - ETA: 5s - loss: 3.6173WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 9/18 [==============>...............] - ETA: 4s - loss: 3.5950WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "10/18 [===============>..............] - ETA: 4s - loss: 3.5840WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "11/18 [=================>............] - ETA: 3s - loss: 3.5833WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "12/18 [===================>..........] - ETA: 3s - loss: 3.5786WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "13/18 [====================>.........] - ETA: 2s - loss: 3.5718WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "14/18 [======================>.......] - ETA: 2s - loss: 3.5677WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "15/18 [========================>.....] - ETA: 1s - loss: 3.5627WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "16/18 [=========================>....] - ETA: 1s - loss: 3.5575WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 3.5530WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "18/18 [==============================] - 11s 621ms/step - loss: 3.5448 - val_loss: 3.6184\n",
            "Epoch 2/15\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 1/18 [>.............................] - ETA: 8s - loss: 2.9354WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 2/18 [==>...........................] - ETA: 8s - loss: 2.6815WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 3/18 [====>.........................] - ETA: 8s - loss: 2.8270WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 4/18 [=====>........................] - ETA: 7s - loss: 2.8592WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 5/18 [=======>......................] - ETA: 6s - loss: 2.9303WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 6/18 [=========>....................] - ETA: 6s - loss: 2.9607WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 7/18 [==========>...................] - ETA: 5s - loss: 2.9588WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 8/18 [============>.................] - ETA: 5s - loss: 2.9740WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 9/18 [==============>...............] - ETA: 4s - loss: 2.9659WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "10/18 [===============>..............] - ETA: 4s - loss: 2.9576WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "11/18 [=================>............] - ETA: 3s - loss: 2.9571WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "12/18 [===================>..........] - ETA: 3s - loss: 2.9560WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "13/18 [====================>.........] - ETA: 2s - loss: 2.9599WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "14/18 [======================>.......] - ETA: 2s - loss: 2.9637WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "15/18 [========================>.....] - ETA: 1s - loss: 2.9704WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "16/18 [=========================>....] - ETA: 1s - loss: 2.9782WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 2.9862WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "18/18 [==============================] - 11s 641ms/step - loss: 3.0018 - val_loss: 3.6869\n",
            "Epoch 3/15\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 1/18 [>.............................] - ETA: 9s - loss: 4.0510WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 2/18 [==>...........................] - ETA: 8s - loss: 3.9198WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 3/18 [====>.........................] - ETA: 7s - loss: 3.6926WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 4/18 [=====>........................] - ETA: 7s - loss: 3.5201WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 5/18 [=======>......................] - ETA: 6s - loss: 3.4290WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 6/18 [=========>....................] - ETA: 6s - loss: 3.3793WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 7/18 [==========>...................] - ETA: 5s - loss: 3.3455WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 8/18 [============>.................] - ETA: 5s - loss: 3.3199WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            " 9/18 [==============>...............] - ETA: 4s - loss: 3.3045WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "10/18 [===============>..............] - ETA: 4s - loss: 3.2951WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "11/18 [=================>............] - ETA: 3s - loss: 3.2652WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "12/18 [===================>..........] - ETA: 3s - loss: 3.2448WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "13/18 [====================>.........] - ETA: 2s - loss: 3.2365WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss.\n",
            "14/18 [======================>.......] - ETA: 2s - loss: 3.2291"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-79aa4ed83d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tfpvae'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         dtype=self._compute_dtype_object)\n\u001b[0m\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5527\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   5528\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5529\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5530\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5531\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vItSit_L26gA"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIxuYMaN-Xon"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}